{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15320528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U llama-index-readers-file pymupdf\n",
    "# %pip install -U llama-index-core\n",
    "# %pip install -U llama-index-llms-azure-openai\n",
    "# %pip install -U llama-index-embeddings-azure-openai\n",
    "# %pip install -U llama-index-vector-stores-chroma\n",
    "# %pip install -U python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75119bc",
   "metadata": {},
   "source": [
    "## 1: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaff34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from llama_index.core import Document\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "docs0 = loader.load(file_path=Path(\"./data/GMDSS_System-IOM_Manual.pdf\"))\n",
    "\n",
    "# Stitch pages together\n",
    "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eaa24b",
   "metadata": {},
   "source": [
    "## 2: Enhanced Hierarchical Parsing with Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202c697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser, get_leaf_nodes\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Azure OpenAI Setup\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "AZURE_CHAT_DEPLOYMENT = os.getenv(\"AZURE_CHAT_DEPLOYMENT\")\n",
    "AZURE_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_EMBEDDING_DEPLOYMENT\")\n",
    "EMBEDDING_DIMENSIONS = int(os.getenv(\"EMBEDDING_DIMENSIONS\", 3072))\n",
    "\n",
    "# Initialize LLM (use gpt-4o-mini for cost savings on summaries)\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    deployment_name=AZURE_CHAT_DEPLOYMENT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=OPENAI_API_VERSION,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    deployment_name=AZURE_EMBEDDING_DEPLOYMENT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=OPENAI_API_VERSION,\n",
    "    dimensions=EMBEDDING_DIMENSIONS,\n",
    ")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ff509",
   "metadata": {},
   "source": [
    "## Generate Parent Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a87c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parent_summaries(nodes):\n",
    "    \"\"\"\n",
    "    Generate concise summaries for parent nodes\n",
    "    \n",
    "    Args:\n",
    "        nodes: List of all nodes from HierarchicalNodeParser\n",
    "        use_mini: Use gpt-4o-mini for cost savings (recommended)\n",
    "    \"\"\"\n",
    "    from llama_index.core.schema import NodeRelationship\n",
    "    \n",
    "    summaries = {}\n",
    "    parent_nodes = [n for n in nodes if NodeRelationship.CHILD in n.relationships]\n",
    "    \n",
    "    summary_llm = llm\n",
    "    \n",
    "    print(f\"Generating summaries for {len(parent_nodes)} parent nodes...\")\n",
    "    print(f\"Using: {summary_llm.model}\")\n",
    "    \n",
    "    for i, node in enumerate(parent_nodes):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Progress: {i}/{len(parent_nodes)}\")\n",
    "        \n",
    "        prompt = f\"\"\"Provide a concise summary (2-3 sentences, max 100 tokens) of this text section: {node.get_content()[:3000]} Summary:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = summary_llm.complete(prompt)\n",
    "            summaries[node.node_id] = response.text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to generate summary for node {node.node_id}: {e}\")\n",
    "            summaries[node.node_id] = node.get_content()[:150] + \"...\"\n",
    "    \n",
    "    print(f\"✓ Generated {len(summaries)} summaries\")\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfaef16",
   "metadata": {},
   "source": [
    "## Enrich Leaf Nodes with Hierarchy Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbcbc399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_leaf_nodes_with_context(nodes, parent_summaries):\n",
    "    \"\"\"\n",
    "    Add parent context to leaf nodes for better retrieval\n",
    "    \n",
    "    Returns: List of enriched TextNode objects\n",
    "    \"\"\"\n",
    "    from llama_index.core.schema import TextNode, NodeRelationship\n",
    "    \n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "    enriched_nodes = []\n",
    "    \n",
    "    print(f\"Enriching {len(leaf_nodes)} leaf nodes with parent context...\")\n",
    "    \n",
    "    for leaf in leaf_nodes:\n",
    "        # Build hierarchy chain\n",
    "        hierarchy_chain = []\n",
    "        current = leaf\n",
    "        \n",
    "        # Traverse up the parent chain\n",
    "        while NodeRelationship.PARENT in current.relationships:\n",
    "            parent_id = current.relationships[NodeRelationship.PARENT].node_id\n",
    "            parent_node = next((n for n in nodes if n.node_id == parent_id), None)\n",
    "            \n",
    "            if parent_node and parent_node.node_id in parent_summaries:\n",
    "                hierarchy_chain.insert(0, parent_summaries[parent_node.node_id])\n",
    "            \n",
    "            current = parent_node\n",
    "            if current is None:\n",
    "                break\n",
    "        \n",
    "        # Create enriched content with context breadcrumbs\n",
    "        if hierarchy_chain:\n",
    "            context_str = \" → \".join(hierarchy_chain)\n",
    "            enriched_content = f\"[CONTEXT: {context_str}]\\n\\n{leaf.get_content()}\"\n",
    "        else:\n",
    "            enriched_content = leaf.get_content()\n",
    "        \n",
    "        # Create new enriched node\n",
    "        enriched_node = TextNode(\n",
    "            text=enriched_content,\n",
    "            metadata={\n",
    "                **leaf.metadata,\n",
    "                \"hierarchy_depth\": len(hierarchy_chain),\n",
    "                \"has_context\": len(hierarchy_chain) > 0,\n",
    "                \"original_node_id\": leaf.node_id\n",
    "            },\n",
    "            relationships=leaf.relationships\n",
    "        )\n",
    "        enriched_node.node_id = leaf.node_id\n",
    "        \n",
    "        enriched_nodes.append(enriched_node)\n",
    "    \n",
    "    print(f\"✓ Enriched {len(enriched_nodes)} nodes\")\n",
    "    return enriched_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27a914",
   "metadata": {},
   "source": [
    "## Create Nodes with Enhanced Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1dc87a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes created: 387\n",
      "Leaf nodes: 247\n",
      "Generating summaries for 140 parent nodes...\n",
      "Using: gpt-4o\n",
      "  Progress: 0/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 10:57:32,163 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:34,376 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:36,684 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:38,109 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:39,841 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:41,286 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:44,224 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:46,058 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:48,227 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:50,876 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 10/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 10:57:52,680 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:54,860 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:56,548 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:57:59,680 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:01,283 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:03,363 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:05,642 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:07,434 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:11,367 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:13,015 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 20/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 10:58:15,056 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:17,093 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:18,796 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:21,560 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:23,364 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:24,884 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:26,573 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:28,431 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:31,024 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:32,634 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 30/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 10:58:34,226 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:36,154 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:38,254 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:40,211 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:41,745 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:44,334 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:46,065 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:48,005 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:49,605 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:51,450 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 40/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 10:58:53,189 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:55,120 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:56,333 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:58:58,505 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:00,370 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:03,647 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:05,342 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:07,958 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:09,373 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:10,815 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 50/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 10:59:12,440 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:14,613 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:16,692 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:18,320 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:21,401 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:22,799 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:24,205 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:26,202 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:28,192 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:29,647 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 60/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 10:59:31,436 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:32,907 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:34,543 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:36,683 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:38,934 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:40,938 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:42,718 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:44,424 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:47,384 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:49,382 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 70/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 10:59:51,504 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:53,003 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:54,760 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:56,542 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:58,233 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 10:59:59,827 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:01,713 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:03,733 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:05,658 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:07,704 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 80/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 11:00:09,561 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:11,771 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:13,873 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:15,682 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:17,435 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:19,163 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:21,324 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:23,484 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:24,867 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:26,569 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 90/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 11:00:28,258 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:29,983 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:31,783 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:33,730 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:36,696 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:38,461 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:40,191 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:42,276 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:44,432 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:46,269 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 100/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 11:00:48,067 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:49,773 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:52,603 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:54,749 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:00:57,288 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:00,178 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:02,579 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:06,265 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:09,275 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:11,555 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 110/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 11:01:12,803 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:15,291 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:16,959 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:18,914 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:22,044 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:23,983 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:27,027 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:30,005 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:32,308 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:35,249 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 120/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 11:01:37,479 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:39,937 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:41,342 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:43,742 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:45,671 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:48,624 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:50,311 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:52,646 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:55,822 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:01:59,628 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 130/140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 11:02:01,890 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:02:04,646 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:02:06,763 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:02:09,235 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:02:11,969 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:02:13,961 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:02:16,110 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:02:17,688 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:02:19,234 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 11:02:21,147 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated 140 summaries\n",
      "Enriching 247 leaf nodes with parent context...\n",
      "✓ Enriched 247 nodes\n"
     ]
    }
   ],
   "source": [
    "# Parse with your existing settings\n",
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[4096, 1024, 512]  # Your current setup\n",
    ")\n",
    "nodes = node_parser.get_nodes_from_documents(docs)\n",
    "\n",
    "print(f\"Total nodes created: {len(nodes)}\")\n",
    "print(f\"Leaf nodes: {len(get_leaf_nodes(nodes))}\")\n",
    "\n",
    "# ENHANCEMENT: Generate summaries and enrich leaf nodes\n",
    "parent_summaries = generate_parent_summaries(nodes)\n",
    "enriched_leaf_nodes = enrich_leaf_nodes_with_context(nodes, parent_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e901441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes created: 387\n",
      "Leaf nodes: 247\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total nodes created: {len(nodes)}\")\n",
    "print(f\"Leaf nodes: {len(get_leaf_nodes(nodes))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0afc4b",
   "metadata": {},
   "source": [
    "## 4: Storage and Indexing (ChromaDB Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21986214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 13:52:23,263 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2026-01-19 13:52:26,648 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:28,600 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:30,954 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:31,879 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:32,671 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:33,523 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:34,989 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:36,506 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:37,346 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:38,669 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:40,201 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:41,168 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:42,471 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:43,986 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:44,887 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:45,752 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:46,589 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:52:47,118 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:52:47,121 - INFO - Retrying request to /embeddings in 5.000000 seconds\n",
      "2026-01-19 13:52:52,374 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:52:52,377 - INFO - Retrying request to /embeddings in 4.000000 seconds\n",
      "2026-01-19 13:52:56,639 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:52:56,642 - WARNING - Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings in 1.0 seconds as it raised RateLimitError: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Your requests to text-embedding-3-large for text-embedding-3-large in East US have exceeded the call rate limit for your current AIServices S0 pricing tier. This request was for Embeddings_Create under Azure OpenAI API version 2024-12-01-preview. Please retry after 2 seconds. To increase your default rate limit, visit: https://aka.ms/oai/quotaincrease.'}}.\n",
      "2026-01-19 13:52:57,898 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:52:57,900 - INFO - Retrying request to /embeddings in 3.000000 seconds\n",
      "2026-01-19 13:53:01,155 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:53:01,158 - INFO - Retrying request to /embeddings in 2.000000 seconds\n",
      "2026-01-19 13:53:03,416 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:53:03,419 - WARNING - Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings in 1.783157777458512 seconds as it raised RateLimitError: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Your requests to text-embedding-3-large for text-embedding-3-large in East US have exceeded the call rate limit for your current AIServices S0 pricing tier. This request was for Embeddings_Create under Azure OpenAI API version 2024-12-01-preview. Please retry after 2 seconds. To increase your default rate limit, visit: https://aka.ms/oai/quotaincrease.'}}.\n",
      "2026-01-19 13:53:05,455 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:53:05,457 - INFO - Retrying request to /embeddings in 3.000000 seconds\n",
      "2026-01-19 13:53:08,721 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:53:08,724 - INFO - Retrying request to /embeddings in 2.000000 seconds\n",
      "2026-01-19 13:53:10,977 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:53:10,980 - WARNING - Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings in 2.4636766733679765 seconds as it raised RateLimitError: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Your requests to text-embedding-3-large for text-embedding-3-large in East US have exceeded the call rate limit for your current AIServices S0 pricing tier. This request was for Embeddings_Create under Azure OpenAI API version 2024-12-01-preview. Please retry after 2 seconds. To increase your default rate limit, visit: https://aka.ms/oai/quotaincrease.'}}.\n",
      "2026-01-19 13:53:13,700 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:53:13,702 - INFO - Retrying request to /embeddings in 4.000000 seconds\n",
      "2026-01-19 13:53:17,962 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:53:17,966 - INFO - Retrying request to /embeddings in 2.000000 seconds\n",
      "2026-01-19 13:53:20,220 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:53:20,223 - WARNING - Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings in 5.712427788319917 seconds as it raised RateLimitError: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Your requests to text-embedding-3-large for text-embedding-3-large in East US have exceeded the call rate limit for your current AIServices S0 pricing tier. This request was for Embeddings_Create under Azure OpenAI API version 2024-12-01-preview. Please retry after 2 seconds. To increase your default rate limit, visit: https://aka.ms/oai/quotaincrease.'}}.\n",
      "2026-01-19 13:53:27,722 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:53:29,369 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:53:30,679 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:53:31,434 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-19 13:53:31,438 - INFO - Retrying request to /embeddings in 1.000000 seconds\n",
      "2026-01-19 13:53:33,044 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:53:34,097 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:53:35,165 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:53:36,268 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 13:53:37,563 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "import chromadb\n",
    "\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)  # Store ALL nodes for AutoMergingRetriever\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"gmdss_manual\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "storage_context_chroma = StorageContext.from_defaults(\n",
    "    vector_store=vector_store,\n",
    "    docstore=docstore\n",
    ")\n",
    "\n",
    "base_index = VectorStoreIndex(\n",
    "    enriched_leaf_nodes,\n",
    "    storage_context=storage_context_chroma,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9859c3c",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4c9746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 14:28:25,572 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2026-01-19 14:28:25,710 - INFO - > Merging 2 nodes into parent node.\n",
      "> Parent node id: 80c9ff4f-0cca-4920-83f3-9be902efd4a0.\n",
      "> Parent node text: General use and navigation\n",
      "98-171832-A\n",
      "Chapter 2: Operation\n",
      "15\n",
      "On-screen key \n",
      "Function \n",
      "16/C \n",
      "Shi...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 2 nodes into parent node.\n",
      "> Parent node id: 80c9ff4f-0cca-4920-83f3-9be902efd4a0.\n",
      "> Parent node text: General use and navigation\n",
      "98-171832-A\n",
      "Chapter 2: Operation\n",
      "15\n",
      "On-screen key \n",
      "Function \n",
      "16/C \n",
      "Shi...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 14:28:29,049 - INFO - HTTP Request: POST https://nilup-mgaf895d-eastus.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY RESPONSE\n",
      "================================================================================\n",
      "When hearing noise or an unwanted signal, briefly push the Volume/Squelch button to ensure the squelch bar is visible on the display. Then, turn the squelch button clockwise until the radio is muted, effectively suppressing the noise.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "retriever = AutoMergingRetriever(\n",
    "    base_retriever, \n",
    "    storage_context_chroma, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "\n",
    "# Test query\n",
    "query_str = \"when Adjusting the squelch level what do When hearing noise or an unwanted signal?\"\n",
    "response = query_engine.query(query_str)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUERY RESPONSE\")\n",
    "print(\"=\"*80)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c792902",
   "metadata": {},
   "source": [
    "## Cost Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707d64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b9115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3c609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
